{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine accuracy:  87 %\n"
     ]
    }
   ],
   "source": [
    "from xml.dom import minidom\n",
    "import re\n",
    "import difflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "MAX_ROWS = 100\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "stopwords = {}\n",
    "key = 0\n",
    "with open(\"Stopwords.txt\") as f:\n",
    "    for line in f:\n",
    "        fLine = line.rstrip(\"\\n\\r\")\n",
    "        stopwords[key] = fLine\n",
    "        key += 1\n",
    "\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def hamming_distance(s1, s2):\n",
    "    assert len(s1) == len(s2)\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "def euclidean_distance(instance1, instance2):\n",
    "    instance1 = np.array(instance1) \n",
    "    instance2 = np.array(instance2)\n",
    "    return np.linalg.norm(instance1 - instance2)\n",
    "\n",
    "def cosine_similarity(v1,v2):\n",
    "    sumxx, sumxy, sumyy,div = 0, 0, 0, 1\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    if(math.sqrt(sumxx*sumyy) > 0):\n",
    "        div = math.sqrt(sumxx*sumyy)\n",
    "    return sumxy/div\n",
    "\n",
    "def computeidf(word, dictionary, wordmap, total):\n",
    "    r = [s for s in dictionary if word.lower() in s.lower() and word.lower() in wordmap.keys()]\n",
    "    occur = len(r)\n",
    "    return math.log((total/occur),2)\n",
    "\n",
    "mydoc = minidom.parse('Anime.xml')\n",
    "items = mydoc.getElementsByTagName('row')\n",
    "words = []\n",
    "label = []\n",
    "index=0\n",
    "wordmap = {}\n",
    "count=0\n",
    "\n",
    "for item in items:\n",
    "    count=count+1\n",
    "    if count==MAX_ROWS:\n",
    "        break\n",
    "    string = remove_tags(item.attributes['Body'].value)\n",
    "    string = string.rstrip()\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('\\n', ' ')\n",
    "    string = string.replace('\\n\\n', ' ')\n",
    "    string = string.replace('\\n\\n\\n', ' ')\n",
    "    string = string.replace('.\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n.', ' .')\n",
    "    string = string.replace('.\\n\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n\\n.', ' .')\n",
    "    string = string.replace('\\n&nbsp;',' ')\n",
    "    string = string.replace('&nbsp;',' ')\n",
    "    words.append(string)\n",
    "    label.append(1)\n",
    "    \n",
    "mydoc = minidom.parse('Cooking.xml')\n",
    "items = mydoc.getElementsByTagName('row')\n",
    "count=0\n",
    "for item in items:\n",
    "    count=count+1\n",
    "    if count==MAX_ROWS:\n",
    "        break\n",
    "    string = remove_tags(item.attributes['Body'].value)\n",
    "    string = string.rstrip()\n",
    "    string = string.replace('\\n', ' ')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('\\n\\n', ' ')\n",
    "    string = string.replace('\\n\\n\\n', ' ')\n",
    "    string = string.replace('.\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n.', ' .')\n",
    "    string = string.replace('.\\n\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n\\n.', ' .')\n",
    "    string = string.replace('\\n&nbsp;',' ')\n",
    "    string = string.replace('&nbsp;',' ')\n",
    "    words.append(string)\n",
    "    label.append(2)\n",
    "    \n",
    "    \n",
    "mydoc = minidom.parse('Arduino.xml')\n",
    "items = mydoc.getElementsByTagName('row')\n",
    "count=0\n",
    "for item in items:\n",
    "    count=count+1\n",
    "    if count==MAX_ROWS:\n",
    "        break\n",
    "    string = remove_tags(item.attributes['Body'].value)\n",
    "    string = string.rstrip()\n",
    "    string = string.replace('\\n', ' ')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('\\n\\n', ' ')\n",
    "    string = string.replace('\\n\\n\\n', ' ')\n",
    "    string = string.replace('.\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n.', ' .')\n",
    "    string = string.replace('.\\n\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n\\n.', ' .')\n",
    "    string = string.replace('\\n&nbsp;',' ')\n",
    "    string = string.replace('&nbsp;',' ')\n",
    "    words.append(string)\n",
    "    label.append(3)\n",
    "\n",
    "    \n",
    "trainwordstotal = words\n",
    "train_properdf = pd.DataFrame({'train_property':words})\n",
    "train_labeldf = pd.DataFrame({'train_label':label})\n",
    "dataframe = pd.concat([train_properdf, train_labeldf], axis=1)\n",
    "\n",
    "\n",
    "index=0\n",
    "for i in range(len(words)):\n",
    "    wordcheck = words[i].rstrip()\n",
    "    wordtotal = wordcheck.split(\" \")\n",
    "    for i in range(len(wordtotal)):\n",
    "        if wordtotal[i].lower() not in stopwords.values():\n",
    "            if wordtotal[i] not in wordmap:\n",
    "                wordmap[wordtotal[i]] = index\n",
    "                index = index + 1\n",
    "                \n",
    "                \n",
    "testl = 3\n",
    "totalrow = 51\n",
    "mydoc = minidom.parse('Dataset/Test/Arduino.xml')\n",
    "items = mydoc.getElementsByTagName('row')\n",
    "testwords = []\n",
    "count=0\n",
    "for item in items:\n",
    "    count=count+1\n",
    "    if count==totalrow:\n",
    "        break\n",
    "    string = remove_tags(item.attributes['Body'].value)\n",
    "    string = string.rstrip()\n",
    "    string = string.replace('\\n', ' ')\n",
    "    string = string.replace(',', ' ')\n",
    "    string = string.replace('\\n\\n', ' ')\n",
    "    string = string.replace('\\n\\n\\n', ' ')\n",
    "    string = string.replace('.\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n.', ' .')\n",
    "    string = string.replace('.\\n\\n\\n', '. ')\n",
    "    string = string.replace('\\n\\n\\n.', ' .')\n",
    "    string = string.replace('\\n&nbsp;',' ')\n",
    "    string = string.replace('&nbsp;',' ')\n",
    "    testwords.append(string)\n",
    "testlabel = [testl]*len(testwords)\n",
    "test_properdf = pd.DataFrame({'test_property':testwords})\n",
    "test_labeldf = pd.DataFrame({'test_label':testlabel})\n",
    "testdataframe = pd.concat([test_properdf, test_labeldf], axis=1)\n",
    "k=3\n",
    "hamming_val = 0\n",
    "euclidean_val = 0\n",
    "cosine_val = 0\n",
    "\n",
    "for wordtest in testwords: \n",
    "    testtfcompute = []\n",
    "    testidfcompute = []\n",
    "    hammingdf = pd.DataFrame(columns=[\"hamming\", \"label\"])\n",
    "    euclideandf = pd.DataFrame(columns=[\"euclidean\", \"label\"])\n",
    "    cosinedf = pd.DataFrame(columns=[\"cosine\", \"label\"])\n",
    "    testVector = [0] * len(wordmap)\n",
    "    hammingTest = [0] * len(wordmap)\n",
    "    wordtest = wordtest.rstrip()\n",
    "    wordtest = wordtest.replace('\\n', ' ')\n",
    "    wordtest = wordtest.replace(',', ' ')\n",
    "    wordtest = wordtest.replace('\\n\\n', ' ')\n",
    "    wordtest = wordtest.replace('\\n\\n\\n', ' ')\n",
    "    wordtest = wordtest.replace('.\\n\\n', '. ')\n",
    "    wordtest = wordtest.replace('\\n\\n.', '. ')\n",
    "    wordtest = wordtest.replace('.\\n\\n\\n', '. ')\n",
    "    wordtest = wordtest.replace('\\n\\n\\n.', ' .')\n",
    "    wordtest = wordtest.replace('\\n&nbsp;',' ')\n",
    "    wordtest = wordtest.replace('&nbsp;',' ')\n",
    "    words = wordtest.split(\" \")\n",
    "    for w in words:\n",
    "        if w in wordmap.keys():\n",
    "            if(hammingTest[wordmap[w]] < 1):\n",
    "                hammingTest[wordmap[w]]=hammingTest[wordmap[w]]+1\n",
    "            testVector[wordmap[w]]=testVector[wordmap[w]]+1\n",
    "            testidfcompute.append(computeidf(w,testwords, totalrow))\n",
    "    if(len(wordtest) == 0):       \n",
    "        testtfcompute = [x / 1 for x in testVector]\n",
    "    else:\n",
    "        testtfcompute = [x / len(wordtest) for x in testVector]\n",
    "    testtfidf = [a*b for a,b in zip(testtfcompute,testidfcompute)]\n",
    "    for index, row in dataframe.iterrows():\n",
    "        traintfcompute = []\n",
    "        trainidfcompute = []\n",
    "        label = row['train_label']\n",
    "        trainwords = row['train_property']\n",
    "        trainvector = [0] * len(wordmap)\n",
    "        hammingtrain = [0]*len(wordmap)\n",
    "        trainwords = trainwords.rstrip()\n",
    "        trainwords = trainwords.replace(',', ' ')\n",
    "        trainwords = trainwords.replace('\\n', ' ')\n",
    "        trainwords = trainwords.replace('\\n\\n', ' ')\n",
    "        trainwords = trainwords.replace('\\n\\n\\n', ' ')\n",
    "        trainwords = trainwords.replace('.\\n\\n', '. ')\n",
    "        trainwords = trainwords.replace('\\n\\n.', ' .')\n",
    "        trainwords = trainwords.replace('.\\n\\n\\n', '. ')\n",
    "        trainwords = trainwords.replace('\\n\\n\\n.', ' .')\n",
    "        trainwords = trainwords.replace('\\n&nbsp;',' ')\n",
    "        trainwords = trainwords.replace('&nbsp;',' ')\n",
    "        wordtrain = trainwords.split(\" \")\n",
    "        for trainw in wordtrain:\n",
    "            if trainw in wordmap.keys(): \n",
    "                if(hammingtrain[wordmap[trainw]] < 1):\n",
    "                    hammingtrain[wordmap[trainw]]=hammingtrain[wordmap[trainw]]+1\n",
    "                trainvector[wordmap[trainw]]=trainvector[wordmap[trainw]]+1\n",
    "                trainidfcompute.append(computeidf(trainw,trainwordstotal, (MAX_ROWS*3)))\n",
    "        if(len(trainwords) == 0):\n",
    "            traintfcompute = [x / 1 for x in trainvector]\n",
    "        else:\n",
    "            traintfcompute = [x / len(trainwords) for x in trainvector]\n",
    "        traintfidf = [a*b for a,b in zip(traintfcompute,trainidfcompute)]\n",
    "        hammingdf = hammingdf.append({\"hamming\": hamming_distance(hammingtrain, hammingTest),\"label\":  label}, ignore_index=True)\n",
    "        euclideandf = euclideandf.append({\"euclidean\": euclidean_distance(trainvector, testVector),\"label\":  label}, ignore_index=True)\n",
    "        if(len(traintfidf) < len(testtfidf)):\n",
    "            cosine_dist = cosine_similarity(traintfidf, testtfidf)\n",
    "        else:\n",
    "            cosine_dist = cosine_similarity(testtfidf, traintfidf)\n",
    "        cosinedf = cosinedf.append({\"cosine\": cosine_dist,\"label\":  label}, ignore_index=True)\n",
    "        \n",
    "    hammingdf = hammingdf.sort_values(by=['hamming'], ascending=True)\n",
    "    euclideandf = euclideandf.sort_values(by=['euclidean'], ascending=True)\n",
    "    cosinedf = cosinedf.sort_values(by=['cosine'], ascending=True)\n",
    "    if(k==1):\n",
    "        finallabel = hammingdf.iloc[0]['label']\n",
    "        if(finallabel == testl):\n",
    "            hamming_val += 1\n",
    "        finallabel = euclideandf.iloc[0]['label']\n",
    "        if(finallabel == testl):\n",
    "            euclidean_val += 1\n",
    "        finallabel = cosinedf.iloc[0]['label']\n",
    "        if(finallabel == testl):\n",
    "            cosine_val += 1\n",
    "    elif(k==3):\n",
    "        hamminglabelrow = hammingdf['label'].head(3).tolist()\n",
    "        hammingdatarow =  hammingdf['hamming'].head(3).tolist()\n",
    "        if(hamminglabelrow.count(testl) > 1):\n",
    "            hamming_val += 1\n",
    "        elif(hamminglabelrow.count(testl) == 1):\n",
    "            if(hamminglabelrow.index(testl) == 0):\n",
    "                hamming_val += 1\n",
    "                \n",
    "        euclideanlabelrow = euclideandf['label'].head(3).tolist()\n",
    "        euclideandatarow =  euclideandf['euclidean'].head(3).tolist()\n",
    "        if(euclideanlabelrow.count(testl) > 1):\n",
    "            euclidean_val += 1\n",
    "        elif(euclideanlabelrow.count(testl) == 1):\n",
    "            if(euclideanlabelrow.index(testl) == 0):\n",
    "                euclidean_val += 1\n",
    "                \n",
    "        cosinelabelrow = euclideandf['label'].head(3).tolist()\n",
    "        cosinedatarow =  euclideandf['cosine'].head(3).tolist()\n",
    "        if(cosinelabelrow.count(testl) > 1):\n",
    "            cosine_val += 1\n",
    "        elif(cosinelabelrow.count(testl) == 1):\n",
    "            if(cosinelabelrow.index(testl) == 0):\n",
    "                cosine_val += 1\n",
    "    elif(k==5):\n",
    "        hamminglabelrow = hammingdf['label'].head(5).tolist()\n",
    "        hammingdatarow =  hammingdf['hamming'].head(5).tolist()\n",
    "        if(hamminglabelrow.count(testl) > 2):\n",
    "            hamming_val += 1\n",
    "        elif(hamminglabelrow.count(testl) == 2):\n",
    "            if(hamminglabelrow.index(testl) == 0):\n",
    "                hamming_val += 1\n",
    "                \n",
    "        euclideanlabelrow = euclideandf['label'].head(5).tolist()\n",
    "        euclideandatarow =  euclideandf['euclidean'].head(5).tolist()\n",
    "        if(euclideanlabelrow.count(testl) > 2):\n",
    "            euclidean_val += 1\n",
    "        elif(euclideanlabelrow.count(testl) == 2):\n",
    "            if(euclideanlabelrow.index(testl) == 0):\n",
    "                euclidean_val += 1\n",
    "                \n",
    "        cosinelabelrow = euclideandf['label'].head(5).tolist()\n",
    "        cosinedatarow =  euclideandf['cosine'].head(5).tolist()\n",
    "        if(cosinelabelrow.count(testl) > 2):\n",
    "            cosine_val += 1\n",
    "        elif(cosinelabelrow.count(testl) == 2):\n",
    "            if(cosinelabelrow.index(testl) == 0):\n",
    "                cosine_val += 1\n",
    "print(\"Hamming accuracy: \", math.ceil((hamming_val/totalrow)*100) , \"%\")\n",
    "print(\"Euclidean accuracy: \", math.ceil((euclidean_val/totalrow)*100) , \"%\")\n",
    "print(\"Cosine accuracy: \", math.ceil((cosine_val/totalrow)*100) , \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
